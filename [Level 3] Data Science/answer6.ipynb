{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: (300404, 3)\n",
      "train size: (198879, 3)\n",
      "test size: (101525, 3)\n",
      "solution size: (101525, 3)\n",
      "weather size: (113880, 8)\n",
      "weather train size: (75816, 8)\n",
      "weather test size: (38064, 8)\n",
      "113880\n",
      "113880\n",
      "weather valid size: (672, 3)\n",
      "672\n",
      "temperature size: (8760, 52)\n",
      "8760\n",
      "building_metadata size: (1449, 6)\n"
     ]
    }
   ],
   "source": [
    "# train 데이터는 '2019-01-01' ~ '2019-08-31'\n",
    "# test 데이터는  '2019-09-01' ~ '2019-12-31'\n",
    "\n",
    "data = pd.read_csv('data.csv', parse_dates=['datetime'])\n",
    "train = data.set_index('datetime').loc['2019-01-01':'2019-08-31'].reset_index()\n",
    "test = data.set_index('datetime').loc['2019-09-01':'2019-12-31'].reset_index()\n",
    "solution = pd.read_csv('data_solution.csv', parse_dates=['datetime'])\n",
    "\n",
    "building = pd.read_csv('building_metadata.csv')\n",
    "weather = pd.read_csv('weather.csv', parse_dates=['datetime'])\n",
    "weather_train = weather.set_index('datetime').loc['2019-01-01':'2019-08-31'].reset_index()\n",
    "weather_test = weather.set_index('datetime').loc['2019-09-01':'2019-12-31'].reset_index()\n",
    "weather_valid = pd.read_csv('weather_valid.csv', parse_dates=['datetime'])\n",
    "\n",
    "temperature = pd.read_csv('temperature.csv', parse_dates=['datetime'])\n",
    "\n",
    "# 데이터 체크\n",
    "print('data size:', data.shape)\n",
    "print('train size:', train.shape)\n",
    "print('test size:', test.shape)\n",
    "print('solution size:', solution.shape)\n",
    "\n",
    "print('weather size:', weather.shape)\n",
    "print('weather train size:', weather_train.shape)\n",
    "print('weather test size:', weather_test.shape)\n",
    "print(weather_train.shape[0] + weather_test.shape[0])\n",
    "print(365 * 24 * 13)\n",
    "\n",
    "print('weather valid size:', weather_valid.shape)\n",
    "print(28 * 24)\n",
    "\n",
    "print('temperature size:', temperature.shape)\n",
    "print(365 * 24)\n",
    "\n",
    "print('building_metadata size:', building.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 0.416\n"
     ]
    }
   ],
   "source": [
    "# Problem 1\n",
    "\n",
    "# Nan인 데이터 값들을 채워넣는 과정이다.\n",
    "\n",
    "# Restore를 수행할 column들\n",
    "columns_to_restore = ['temperature','dew_point','cloud','rain_hourly','air_pressure','wind_direction']\n",
    "\n",
    "# train과 test 날씨 데이터를 결합한다.\n",
    "weather_df = pd.concat([weather_train, weather_test])\n",
    "\n",
    "# region_id와 datetime으로 인덱스를 설정하여 탐색 속도를 높인다.\n",
    "weather_df = weather_df.set_index(['region_id', 'datetime']).sort_index()\n",
    "\n",
    "# interpolation을 이용하여 비어있는 값들을 채워야 한다.\n",
    "# 그렇기 위해서는 먼저 데이터를 time series 데이터로 추출해야 한다.\n",
    "# 각각의 region 마다 독립적인 time series 데이터가 있기 때문에 time series 별로 따로 추출해야 한다.\n",
    "for column in columns_to_restore:\n",
    "    for region_id in range(13):\n",
    "        s = weather_df.loc[region_id, column].copy()\n",
    "        \n",
    "        # interpolation으로 값을 채울때 limit_direction을 both로 선택하여 모든 값들을 채울 수 있도록 한다.\n",
    "        # cloud 칼럼의 경우 0, 2, 4, 6, 8로 이루어진 값이기 때문에 \n",
    "        # 해당 값들로 정수화 하는 과정이 추가로 필요하다.\n",
    "        if column == 'cloud':\n",
    "            interpolation = (s/2).interpolate(limit_direction='both')\n",
    "            interpolation[interpolation.notnull()] = interpolation[interpolation.notnull()].astype(np.int8)*2\n",
    "        else:\n",
    "            interpolation = s.interpolate(limit_direction='both')\n",
    "        weather_df.loc[region_id, column].iloc[:] = interpolation\n",
    "        \n",
    "# 주어진 valid 데이터(weather_valid.csv)를 이용하여 interpolate의 정확도를 테스트한다.\n",
    "# valid 데이터는 region_id = 9 의 2월 데이터가 빠짐없이 들어있다.\n",
    "# 이를 이용하여 interpolate된 값과 correlation을 계산한다.\n",
    "column = columns_to_restore[0]\n",
    "region_id = 9\n",
    "st  = '2019-02-01 00:00:00'\n",
    "end = '2019-02-28 23:59:59'\n",
    "index_slice = slice(st, end)\n",
    "\n",
    "weather_valid_df = weather_valid.copy()\n",
    "weather_valid_df = weather_valid_df.set_index(['region_id', 'datetime'], drop=False).sort_index()\n",
    "\n",
    "# RMSE 값을 계산하여 출력한다.\n",
    "rmse = ((weather_df.loc[region_id, column] - weather_valid_df.loc[region_id, column]) ** 2).mean() ** .5\n",
    "print('Answer:', round(rmse,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8760 54\n",
      "Answer: minneapolis, austin\n"
     ]
    }
   ],
   "source": [
    "# Problem 2\n",
    "\n",
    "# 현재 주어진 데이터의 region은 번호로 주어져 있고 실제 도시 이름을 모른다.\n",
    "# 이를 다른 데이터를 이용하여 실제 도시 이름을 유추해본다.\n",
    "# 이때 다른 데이터와 비교할 metric으로 dynamic time warping (DTW)를 사용한다.\n",
    "# temperature.csv에서는 여러 도시별 시간별 기온이 들어있다.\n",
    "# weather 데이터와 temperature 추가 데이터의 datetime은 같은 표준시에 맞춰져 있기 떄문에 \n",
    "# 따로 datetime를 처리할 필요는 없다.\n",
    "\n",
    "weather_df = weather_df.reset_index()\n",
    "\n",
    "# weather 데이터에서 temperature 데이터를 추출한다.\n",
    "df_temperature_pivot = weather_df.reset_index().pivot_table(index='datetime', columns='region_id', values='temperature')\n",
    "df_temperature_pivot = df_temperature_pivot.loc[:,[0,1]]\n",
    "\n",
    "# 추가 데이터의 temperature 데이터를 가져와서 weather 데이터와 datetime을 이용하여 merge 한다.\n",
    "# 그러기 위해서 양쪽 데이터의 index를 datetime으로 설정해 두어야 한다.\n",
    "# merge 할때 key join 방법으로 inner를 선택한다.\n",
    "temperature_df = temperature.copy()\n",
    "temperature_df.set_index('datetime', inplace=True)\n",
    "temperature_df = temperature_df.merge(df_temperature_pivot, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "print(temperature_df.shape[0], temperature_df.shape[1]+1) # datetime column Count 추가\n",
    "\n",
    "# merge된 데이터에서 weather 데이터와 temperature 추가 데이터를 분리한다.\n",
    "col_regions = [i for i in range(2)]\n",
    "col_cities = [col for col in temperature_df.columns if col not in col_regions]\n",
    "temperature_regions = [temperature_df[col].copy() for col in temperature_df.columns if col in col_regions]\n",
    "temperature_cities = [temperature_df[col].copy() for col in temperature_df.columns if col in col_cities]\n",
    "\n",
    "# RMSE를 계산한다.\n",
    "def calc_rmse(a, b):\n",
    "    return (((a - b)**2).abs()).mean()**(1/2)\n",
    "\n",
    "rmse_table = []\n",
    "for i, temperature_city in enumerate(temperature_cities):\n",
    "    rmse_row = []\n",
    "    for j, temperature_region in enumerate(temperature_regions):\n",
    "        rmse = calc_rmse(temperature_region, temperature_city)\n",
    "        rmse_row.append(rmse)\n",
    "        \n",
    "    rmse_table.append(rmse_row)\n",
    "    \n",
    "df_rmse = np.array(rmse_table)\n",
    "\n",
    "# RMSE가 가장 작은 index및 그 값을 찾아서 dataframe으로 만든다.\n",
    "df_findCity_indicies = df_rmse.argmin(axis=0)\n",
    "df_findCity_rmse = df_rmse.min(axis=0)\n",
    "df_findCity = pd.DataFrame.from_dict({\n",
    "    #'dtw': df_findCity_rmse,\n",
    "    'city': np.array(col_cities)[df_findCity_indicies],\n",
    "    'region': col_regions,\n",
    "})\n",
    "\n",
    "# matching된 city들을 출력한다.\n",
    "print('Answer:', df_findCity['city'][0]+', '+df_findCity['city'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198879, 14)\n",
      "Answer: air_pressure 0.255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z3/0n9cxghs7fz_xy1kjbg201gr0000gn/T/ipykernel_21271/3141029330.py:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df = df.groupby(['region_id', 'hr']).mean()\n"
     ]
    }
   ],
   "source": [
    "# Problem 3\n",
    "\n",
    "# train 데이터와 building 데이터와 weather 데이터를 merge 한다.\n",
    "# merge 할때 key joint 방법은 'left'를 사용한다.\n",
    "# join 할때 사용할 key 값들로 region_id와 date_time를 사용한다.\n",
    "train_df = train.copy()\n",
    "train_df = train_df.merge(building, on='user_id', how='left')\n",
    "train_df_merged = train_df.merge(weather_df, on=['region_id', 'datetime'], how='left')\n",
    "print(train_df_merged.shape)\n",
    "\n",
    "df = train_df_merged.copy()\n",
    "df['hr'] = df['datetime'].dt.hour\n",
    "df = df.groupby(['region_id', 'hr']).mean()\n",
    "\n",
    "# column은 time에 대해 변하는 변수들만 사용한다. user_id나 area 등 시간에 독립적인 값들은 제외한다.\n",
    "corrs = []\n",
    "df = df.reset_index()\n",
    "columns = ['generate', 'temperature', 'cloud', 'dew_point', 'rain_hourly', 'air_pressure', 'wind_direction']\n",
    "\n",
    "total_corr = np.zeros([len(columns), len(columns)])\n",
    "count = np.zeros([len(columns), len(columns)])\n",
    "\n",
    "# time series는 region 별로 독립적이기 때문에 region_id별로 추출해서 계산해야 한다.\n",
    "# 각 region 별로 correation 값을 계산후 이를 마지막에 평균으로 계산한다. \n",
    "for region_id in df['region_id'].unique():\n",
    "    # region_id (2, 4, 7, 12) 에는 NaN 값이 있기 때문에 해당 데이터들은 제외한다.\n",
    "    if region_id in [2, 4, 7, 12]:\n",
    "        continue\n",
    "\n",
    "    series = df[df['region_id'] == region_id]\n",
    "    series = series[columns]\n",
    "\n",
    "    # correation 값을 계산한다. self-correlation을 계산하면 모든 column 조합의 correlation이 나온다.\n",
    "    corr = np.array(series.corr('pearson'))\n",
    "\n",
    "    # correation 값을 더해준다.\n",
    "    total_corr += corr\n",
    "    count += 1\n",
    "\n",
    "# total_corr를 count로 나눠주면 평균 correlation 값이 나온다.\n",
    "mean_corr = total_corr / count\n",
    "max_index = np.argmax(mean_corr[0][1:])\n",
    "print('Answer:',columns[max_index+1],round(mean_corr[0][max_index+1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:41:41.827041Z",
     "start_time": "2023-06-29T12:41:41.752369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Problem 4\n",
    "\n",
    "# weather 데이터가 local 시간에 맞춰져 있지 않고 표준시이기 때문에 데이터가 shift 되어 있다.\n",
    "# 이에 반해 train 데이터는 local 시간에 맞춰져 있다.\n",
    "# 학습 성능 향상을 위해 weather 데이터를 local 시간에 맞추는 작업을 한다.\n",
    "\n",
    "weather_df = weather_df.reset_index(drop=True)\n",
    "weather_key = ['region_id', 'datetime']\n",
    "temp_series = weather_df[weather_key + ['temperature']].drop_duplicates(subset=weather_key).sort_values(by=weather_key).copy()\n",
    "\n",
    "# 각 region별, 시간별 데이터를 평균낸다.\n",
    "df_temp = temp_series.groupby(['region_id', temp_series.datetime.dt.hour])['temperature'].mean().unstack(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:43:56.901651Z",
     "start_time": "2023-06-29T12:43:56.873379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>datetime</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.022900</td>\n",
       "      <td>11.372781</td>\n",
       "      <td>10.645557</td>\n",
       "      <td>10.083826</td>\n",
       "      <td>9.474530</td>\n",
       "      <td>8.996183</td>\n",
       "      <td>8.512137</td>\n",
       "      <td>8.163858</td>\n",
       "      <td>7.769511</td>\n",
       "      <td>7.434890</td>\n",
       "      <td>...</td>\n",
       "      <td>8.088566</td>\n",
       "      <td>9.088689</td>\n",
       "      <td>10.200425</td>\n",
       "      <td>11.180338</td>\n",
       "      <td>11.991530</td>\n",
       "      <td>12.629301</td>\n",
       "      <td>13.033142</td>\n",
       "      <td>13.152475</td>\n",
       "      <td>13.022868</td>\n",
       "      <td>12.584868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.330342</td>\n",
       "      <td>23.099110</td>\n",
       "      <td>22.027626</td>\n",
       "      <td>21.172808</td>\n",
       "      <td>20.388548</td>\n",
       "      <td>19.685128</td>\n",
       "      <td>19.148685</td>\n",
       "      <td>18.690521</td>\n",
       "      <td>18.310521</td>\n",
       "      <td>17.985516</td>\n",
       "      <td>...</td>\n",
       "      <td>18.624288</td>\n",
       "      <td>20.142098</td>\n",
       "      <td>21.737990</td>\n",
       "      <td>23.210243</td>\n",
       "      <td>24.428679</td>\n",
       "      <td>25.381439</td>\n",
       "      <td>26.078797</td>\n",
       "      <td>26.330402</td>\n",
       "      <td>26.154854</td>\n",
       "      <td>25.506192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.376419</td>\n",
       "      <td>8.199936</td>\n",
       "      <td>8.101742</td>\n",
       "      <td>7.996424</td>\n",
       "      <td>7.965133</td>\n",
       "      <td>8.006325</td>\n",
       "      <td>8.293498</td>\n",
       "      <td>8.700607</td>\n",
       "      <td>9.261593</td>\n",
       "      <td>9.965913</td>\n",
       "      <td>...</td>\n",
       "      <td>12.271845</td>\n",
       "      <td>12.202457</td>\n",
       "      <td>11.915489</td>\n",
       "      <td>11.435187</td>\n",
       "      <td>10.838037</td>\n",
       "      <td>10.269457</td>\n",
       "      <td>9.715968</td>\n",
       "      <td>9.265174</td>\n",
       "      <td>8.925658</td>\n",
       "      <td>8.631394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.667224</td>\n",
       "      <td>14.711541</td>\n",
       "      <td>13.544827</td>\n",
       "      <td>12.208987</td>\n",
       "      <td>11.134454</td>\n",
       "      <td>10.400034</td>\n",
       "      <td>9.825934</td>\n",
       "      <td>9.374487</td>\n",
       "      <td>9.001732</td>\n",
       "      <td>8.631104</td>\n",
       "      <td>...</td>\n",
       "      <td>8.144292</td>\n",
       "      <td>9.473725</td>\n",
       "      <td>11.108468</td>\n",
       "      <td>12.677937</td>\n",
       "      <td>14.019620</td>\n",
       "      <td>14.988761</td>\n",
       "      <td>15.623997</td>\n",
       "      <td>16.089498</td>\n",
       "      <td>16.346393</td>\n",
       "      <td>16.248333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.042052</td>\n",
       "      <td>9.724424</td>\n",
       "      <td>9.463399</td>\n",
       "      <td>9.225585</td>\n",
       "      <td>9.080333</td>\n",
       "      <td>9.094338</td>\n",
       "      <td>9.351110</td>\n",
       "      <td>9.896836</td>\n",
       "      <td>10.634776</td>\n",
       "      <td>11.554932</td>\n",
       "      <td>...</td>\n",
       "      <td>14.779402</td>\n",
       "      <td>14.730594</td>\n",
       "      <td>14.413032</td>\n",
       "      <td>13.902055</td>\n",
       "      <td>13.317178</td>\n",
       "      <td>12.647662</td>\n",
       "      <td>12.053336</td>\n",
       "      <td>11.492138</td>\n",
       "      <td>10.988372</td>\n",
       "      <td>10.477553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.327903</td>\n",
       "      <td>17.502655</td>\n",
       "      <td>16.517356</td>\n",
       "      <td>15.587233</td>\n",
       "      <td>14.918247</td>\n",
       "      <td>14.466543</td>\n",
       "      <td>14.076059</td>\n",
       "      <td>13.752998</td>\n",
       "      <td>13.480397</td>\n",
       "      <td>13.241664</td>\n",
       "      <td>...</td>\n",
       "      <td>12.574615</td>\n",
       "      <td>13.087957</td>\n",
       "      <td>14.049564</td>\n",
       "      <td>15.162965</td>\n",
       "      <td>16.194320</td>\n",
       "      <td>17.217119</td>\n",
       "      <td>18.090094</td>\n",
       "      <td>18.708229</td>\n",
       "      <td>18.998633</td>\n",
       "      <td>18.896613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.626301</td>\n",
       "      <td>15.864233</td>\n",
       "      <td>15.293817</td>\n",
       "      <td>14.781037</td>\n",
       "      <td>14.373689</td>\n",
       "      <td>13.983502</td>\n",
       "      <td>13.664662</td>\n",
       "      <td>13.298744</td>\n",
       "      <td>12.988890</td>\n",
       "      <td>12.687968</td>\n",
       "      <td>...</td>\n",
       "      <td>14.870247</td>\n",
       "      <td>15.995347</td>\n",
       "      <td>17.037479</td>\n",
       "      <td>17.966584</td>\n",
       "      <td>18.712219</td>\n",
       "      <td>19.047265</td>\n",
       "      <td>19.133233</td>\n",
       "      <td>18.852457</td>\n",
       "      <td>18.202023</td>\n",
       "      <td>17.437406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.282861</td>\n",
       "      <td>8.372239</td>\n",
       "      <td>7.607347</td>\n",
       "      <td>7.019446</td>\n",
       "      <td>6.502322</td>\n",
       "      <td>6.062824</td>\n",
       "      <td>5.653475</td>\n",
       "      <td>5.236591</td>\n",
       "      <td>4.842400</td>\n",
       "      <td>4.500991</td>\n",
       "      <td>...</td>\n",
       "      <td>7.182598</td>\n",
       "      <td>8.216891</td>\n",
       "      <td>9.146636</td>\n",
       "      <td>9.942258</td>\n",
       "      <td>10.577820</td>\n",
       "      <td>10.947912</td>\n",
       "      <td>11.117118</td>\n",
       "      <td>11.151393</td>\n",
       "      <td>10.742728</td>\n",
       "      <td>10.063187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.142187</td>\n",
       "      <td>29.398484</td>\n",
       "      <td>28.361064</td>\n",
       "      <td>27.178050</td>\n",
       "      <td>26.030607</td>\n",
       "      <td>24.972530</td>\n",
       "      <td>23.969644</td>\n",
       "      <td>23.214699</td>\n",
       "      <td>22.424639</td>\n",
       "      <td>21.650726</td>\n",
       "      <td>...</td>\n",
       "      <td>19.797557</td>\n",
       "      <td>20.876767</td>\n",
       "      <td>22.652283</td>\n",
       "      <td>24.528963</td>\n",
       "      <td>26.196329</td>\n",
       "      <td>27.557329</td>\n",
       "      <td>28.713868</td>\n",
       "      <td>29.602904</td>\n",
       "      <td>30.167922</td>\n",
       "      <td>30.360064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.541849</td>\n",
       "      <td>22.559254</td>\n",
       "      <td>21.854864</td>\n",
       "      <td>21.339731</td>\n",
       "      <td>20.891603</td>\n",
       "      <td>20.454187</td>\n",
       "      <td>20.096653</td>\n",
       "      <td>19.767744</td>\n",
       "      <td>19.484858</td>\n",
       "      <td>19.299397</td>\n",
       "      <td>...</td>\n",
       "      <td>23.080087</td>\n",
       "      <td>24.649603</td>\n",
       "      <td>25.879758</td>\n",
       "      <td>26.708785</td>\n",
       "      <td>27.179146</td>\n",
       "      <td>27.461470</td>\n",
       "      <td>27.262215</td>\n",
       "      <td>26.742519</td>\n",
       "      <td>25.978080</td>\n",
       "      <td>24.763562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.540836</td>\n",
       "      <td>13.530594</td>\n",
       "      <td>12.814461</td>\n",
       "      <td>12.158890</td>\n",
       "      <td>11.644224</td>\n",
       "      <td>11.133995</td>\n",
       "      <td>10.714178</td>\n",
       "      <td>10.336301</td>\n",
       "      <td>10.014489</td>\n",
       "      <td>9.775795</td>\n",
       "      <td>...</td>\n",
       "      <td>13.190096</td>\n",
       "      <td>14.464612</td>\n",
       "      <td>15.533753</td>\n",
       "      <td>16.418402</td>\n",
       "      <td>17.019749</td>\n",
       "      <td>17.402032</td>\n",
       "      <td>17.364977</td>\n",
       "      <td>17.067489</td>\n",
       "      <td>16.401333</td>\n",
       "      <td>15.514890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.196049</td>\n",
       "      <td>9.043065</td>\n",
       "      <td>8.269557</td>\n",
       "      <td>7.680159</td>\n",
       "      <td>7.261546</td>\n",
       "      <td>6.881164</td>\n",
       "      <td>6.639814</td>\n",
       "      <td>6.355857</td>\n",
       "      <td>6.090430</td>\n",
       "      <td>5.879125</td>\n",
       "      <td>...</td>\n",
       "      <td>9.647059</td>\n",
       "      <td>10.882566</td>\n",
       "      <td>11.837142</td>\n",
       "      <td>12.573365</td>\n",
       "      <td>13.166146</td>\n",
       "      <td>13.520420</td>\n",
       "      <td>13.529127</td>\n",
       "      <td>13.251116</td>\n",
       "      <td>12.569074</td>\n",
       "      <td>11.506881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.703470</td>\n",
       "      <td>9.551461</td>\n",
       "      <td>9.392374</td>\n",
       "      <td>9.247808</td>\n",
       "      <td>9.160646</td>\n",
       "      <td>9.161657</td>\n",
       "      <td>9.272211</td>\n",
       "      <td>9.637104</td>\n",
       "      <td>10.145238</td>\n",
       "      <td>10.804377</td>\n",
       "      <td>...</td>\n",
       "      <td>13.048676</td>\n",
       "      <td>12.982785</td>\n",
       "      <td>12.736301</td>\n",
       "      <td>12.320959</td>\n",
       "      <td>11.868174</td>\n",
       "      <td>11.378904</td>\n",
       "      <td>10.850868</td>\n",
       "      <td>10.470776</td>\n",
       "      <td>10.216758</td>\n",
       "      <td>9.973470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "datetime          0          1          2          3          4          5   \\\n",
       "region_id                                                                     \n",
       "0          12.022900  11.372781  10.645557  10.083826   9.474530   8.996183   \n",
       "1          24.330342  23.099110  22.027626  21.172808  20.388548  19.685128   \n",
       "2           8.376419   8.199936   8.101742   7.996424   7.965133   8.006325   \n",
       "3          15.667224  14.711541  13.544827  12.208987  11.134454  10.400034   \n",
       "4          10.042052   9.724424   9.463399   9.225585   9.080333   9.094338   \n",
       "5          18.327903  17.502655  16.517356  15.587233  14.918247  14.466543   \n",
       "6          16.626301  15.864233  15.293817  14.781037  14.373689  13.983502   \n",
       "7           9.282861   8.372239   7.607347   7.019446   6.502322   6.062824   \n",
       "8          30.142187  29.398484  28.361064  27.178050  26.030607  24.972530   \n",
       "9          23.541849  22.559254  21.854864  21.339731  20.891603  20.454187   \n",
       "10         14.540836  13.530594  12.814461  12.158890  11.644224  11.133995   \n",
       "11         10.196049   9.043065   8.269557   7.680159   7.261546   6.881164   \n",
       "12          9.703470   9.551461   9.392374   9.247808   9.160646   9.161657   \n",
       "\n",
       "datetime          6          7          8          9   ...         14  \\\n",
       "region_id                                              ...              \n",
       "0           8.512137   8.163858   7.769511   7.434890  ...   8.088566   \n",
       "1          19.148685  18.690521  18.310521  17.985516  ...  18.624288   \n",
       "2           8.293498   8.700607   9.261593   9.965913  ...  12.271845   \n",
       "3           9.825934   9.374487   9.001732   8.631104  ...   8.144292   \n",
       "4           9.351110   9.896836  10.634776  11.554932  ...  14.779402   \n",
       "5          14.076059  13.752998  13.480397  13.241664  ...  12.574615   \n",
       "6          13.664662  13.298744  12.988890  12.687968  ...  14.870247   \n",
       "7           5.653475   5.236591   4.842400   4.500991  ...   7.182598   \n",
       "8          23.969644  23.214699  22.424639  21.650726  ...  19.797557   \n",
       "9          20.096653  19.767744  19.484858  19.299397  ...  23.080087   \n",
       "10         10.714178  10.336301  10.014489   9.775795  ...  13.190096   \n",
       "11          6.639814   6.355857   6.090430   5.879125  ...   9.647059   \n",
       "12          9.272211   9.637104  10.145238  10.804377  ...  13.048676   \n",
       "\n",
       "datetime          15         16         17         18         19         20  \\\n",
       "region_id                                                                     \n",
       "0           9.088689  10.200425  11.180338  11.991530  12.629301  13.033142   \n",
       "1          20.142098  21.737990  23.210243  24.428679  25.381439  26.078797   \n",
       "2          12.202457  11.915489  11.435187  10.838037  10.269457   9.715968   \n",
       "3           9.473725  11.108468  12.677937  14.019620  14.988761  15.623997   \n",
       "4          14.730594  14.413032  13.902055  13.317178  12.647662  12.053336   \n",
       "5          13.087957  14.049564  15.162965  16.194320  17.217119  18.090094   \n",
       "6          15.995347  17.037479  17.966584  18.712219  19.047265  19.133233   \n",
       "7           8.216891   9.146636   9.942258  10.577820  10.947912  11.117118   \n",
       "8          20.876767  22.652283  24.528963  26.196329  27.557329  28.713868   \n",
       "9          24.649603  25.879758  26.708785  27.179146  27.461470  27.262215   \n",
       "10         14.464612  15.533753  16.418402  17.019749  17.402032  17.364977   \n",
       "11         10.882566  11.837142  12.573365  13.166146  13.520420  13.529127   \n",
       "12         12.982785  12.736301  12.320959  11.868174  11.378904  10.850868   \n",
       "\n",
       "datetime          21         22         23  \n",
       "region_id                                   \n",
       "0          13.152475  13.022868  12.584868  \n",
       "1          26.330402  26.154854  25.506192  \n",
       "2           9.265174   8.925658   8.631394  \n",
       "3          16.089498  16.346393  16.248333  \n",
       "4          11.492138  10.988372  10.477553  \n",
       "5          18.708229  18.998633  18.896613  \n",
       "6          18.852457  18.202023  17.437406  \n",
       "7          11.151393  10.742728  10.063187  \n",
       "8          29.602904  30.167922  30.360064  \n",
       "9          26.742519  25.978080  24.763562  \n",
       "10         17.067489  16.401333  15.514890  \n",
       "11         13.251116  12.569074  11.506881  \n",
       "12         10.470776  10.216758   9.973470  \n",
       "\n",
       "[13 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:44:52.233575Z",
     "start_time": "2023-06-29T12:44:52.228807Z"
    }
   },
   "outputs": [],
   "source": [
    "# 기온의 peak가 14시가 되도록 맞춘다. (오후 2시가 가장 덥다는 가정이다.)\n",
    "# peak 값이 14에서 얼마나 떨어져 있는지 offset을 계산한다.\n",
    "region_ids_offsets = pd.Series(df_temp.values.argmax(axis=1) - 14)\n",
    "region_ids_offsets.index.name = 'region_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:45:00.338218Z",
     "start_time": "2023-06-29T12:45:00.328503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region_id\n",
       "0     7\n",
       "1     7\n",
       "2     0\n",
       "3     8\n",
       "4     0\n",
       "5     8\n",
       "6     6\n",
       "7     7\n",
       "8     9\n",
       "9     5\n",
       "10    5\n",
       "11    6\n",
       "12    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_ids_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:45:18.694336Z",
     "start_time": "2023-06-29T12:45:18.685816Z"
    }
   },
   "outputs": [],
   "source": [
    "# 계산된 값을 weather 데이터의 datetime에서 빼준다. 이때 offset 값을 timedelta hour로 변환해야한다.\n",
    "weather_df_aligned = weather_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:45:24.204686Z",
     "start_time": "2023-06-29T12:45:24.189464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7\n",
       "1         7\n",
       "2         7\n",
       "3         7\n",
       "4         7\n",
       "         ..\n",
       "113875    0\n",
       "113876    0\n",
       "113877    0\n",
       "113878    0\n",
       "113879    0\n",
       "Name: region_id, Length: 113880, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df_aligned.region_id.map(region_ids_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:46:02.741199Z",
     "start_time": "2023-06-29T12:46:02.731412Z"
    }
   },
   "outputs": [],
   "source": [
    "weather_df_aligned['offset'] = weather_df_aligned.region_id.map(region_ids_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:46:17.681638Z",
     "start_time": "2023-06-29T12:46:17.655031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0 days 07:00:00\n",
       "1        0 days 07:00:00\n",
       "2        0 days 07:00:00\n",
       "3        0 days 07:00:00\n",
       "4        0 days 07:00:00\n",
       "               ...      \n",
       "113875   0 days 00:00:00\n",
       "113876   0 days 00:00:00\n",
       "113877   0 days 00:00:00\n",
       "113878   0 days 00:00:00\n",
       "113879   0 days 00:00:00\n",
       "Name: offset, Length: 113880, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_timedelta(weather_df_aligned['offset'], unit='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:46:26.928346Z",
     "start_time": "2023-06-29T12:46:26.906619Z"
    }
   },
   "outputs": [],
   "source": [
    "weather_df_aligned['datetime'] = (weather_df_aligned.datetime - pd.to_timedelta(weather_df_aligned.offset, unit='H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T12:47:00.712923Z",
     "start_time": "2023-06-29T12:47:00.424161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91140, 15)\n",
      "Answer: 1.661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z3/0n9cxghs7fz_xy1kjbg201gr0000gn/T/ipykernel_21271/1500882462.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[features.isnull()] = 0\n",
      "/var/folders/z3/0n9cxghs7fz_xy1kjbg201gr0000gn/T/ipykernel_21271/1500882462.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[features.isnull()] = 0\n",
      "/Users/jihunkang/.pyenv/versions/3.9.1/envs/main/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df_merged_aligned = train_df.merge(weather_df_aligned, on=['region_id', 'datetime'], how='left')                    \n",
    "train_df_merged_aligned = train_df.merge(weather_df_aligned, on=['region_id', 'datetime'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "train_df = train_df_merged_aligned.copy()\n",
    "\n",
    "not_null_list = pd.notnull(train_df['construct_year'])\n",
    "\n",
    "df = train_df.copy()[not_null_list]\n",
    "print(df.shape)\n",
    "\n",
    "# error metric을 Root Mean Squared Logarithmic Error 을 사용한다.\n",
    "df['generate'] = np.log1p(df['generate'])#.astype(np.float32)\n",
    "\n",
    "# datetime을 그대로 사용하지 않고 분리해서 사용한다.\n",
    "# 전체 시간에 대해 regression하는 것보다 월별, 일별, 시간별로 regression 하는게 더 정확하다.\n",
    "df['hour'] = np.uint8(df['datetime'].dt.hour)\n",
    "df['day'] = np.uint8(df['datetime'].dt.day)\n",
    "df['month'] = np.uint8(df['datetime'].dt.month)\n",
    "\n",
    "# datetime 칼럼을 제거한다.\n",
    "for col in df.columns:\n",
    "    if col in ['datetime']:\n",
    "        del df[col]\n",
    "    \n",
    "df_train = df\n",
    "\n",
    "# feature들을 따로 빼준다.\n",
    "# 먼저 예측할 값인 generate를 제외하고 추가로 categorical feature들인 'user_id', 'usage', 'region_id'를 제거한다.\n",
    "# 위에서 offset 칼럼이 생겼기 때문에 이 또한 제거한다. \n",
    "# 최종적으로 사용되는 feature들은 아래와 같다.\n",
    "# ['area', 'construct_year', 'num_floors', 'temperature', 'cloud', 'dew_point', 'rain_hourly', 'air_pressure',\n",
    "# 'wind_direction', 'hour', 'day', 'month']\n",
    "target = 'generate'\n",
    "categorical_features = ['user_id', 'usage', 'region_id']\n",
    "feature_cols = [col for col in df_train.columns if col not in [target, 'offset'] + categorical_features]\n",
    "# print('Used features:', feature_cols)\n",
    "\n",
    "features = df_train[feature_cols]\n",
    "\n",
    "# Nan인 값들은 0으로 채워준다.\n",
    "features[features.isnull()] = 0\n",
    "    \n",
    "label = df_train[target]\n",
    "\n",
    "train_features = features.copy()\n",
    "train_label = label.copy()\n",
    "\n",
    "# Linear Regression\n",
    "clf = LinearRegression(fit_intercept=True, normalize=False)\n",
    "clf.fit(train_features, train_label)\n",
    "\n",
    "# train 데이터 에러값을 계산하고 위해 train 데이터의 feature들을 이용하여 predict 한다.\n",
    "predicted = clf.predict(train_features)\n",
    "expected = label\n",
    "\n",
    "pd.DataFrame.from_dict({\n",
    "    'features': feature_cols,\n",
    "    'std': train_features.std(),\n",
    "    'coef': clf.coef_,\n",
    "    'importance': np.abs(clf.coef_) * train_features.std()\n",
    "})\n",
    "\n",
    "# RMSE 출력\n",
    "print('Answer:',round(np.sqrt(np.mean((predicted - expected) ** 2)),3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 1.523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\giwoong.bae\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\giwoong.bae\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py:3515: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._where(-key, value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Problem 5\n",
    "\n",
    "train_df = train_df_merged_aligned.copy()\n",
    "\n",
    "df = train_df.copy()[not_null_list]\n",
    "\n",
    "df['generate'] = np.log1p(df['generate'])#.astype(np.float32)\n",
    "\n",
    "df['hour'] = np.uint8(df['datetime'].dt.hour)\n",
    "df['day'] = np.uint8(df['datetime'].dt.day)\n",
    "df['month'] = np.uint8(df['datetime'].dt.month)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col in ['datetime', 'row_id']:\n",
    "        del df[col]\n",
    "    \n",
    "# usage는 categorical feature이기 때문에 regression에 사용할 수 없다.\n",
    "# usage를 feature로 사용하기 위해 usage를 continuous 값으로 변환한다.\n",
    "# 각각의 usage 별로 generate 값의 평균을 내고 해당 평균을 usage 값으로 사용한다.\n",
    "# 이 과정을 log 도메인에서 진행해야 한다. (log1p 함수 이후에 수행해야함)\n",
    "usage_scale = df.groupby('usage', as_index=False)['generate'].mean()\n",
    "usage_scale.columns = ['usage', 'usage_numeric']\n",
    "df = pd.merge(df, usage_scale, how='left', on='usage')\n",
    "\n",
    "# area와 num_floors feature들을 log 도메인으로 변환시켜준다.\n",
    "df['area'] = np.log1p(df['area'])\n",
    "df['num_floors'] = np.log1p(df['num_floors'])\n",
    "    \n",
    "df_train = df\n",
    "\n",
    "target = 'generate'\n",
    "categorical_features = ['user_id', 'usage', 'region_id']\n",
    "feature_cols = [col for col in df_train.columns if col not in [target, 'offset'] + categorical_features]\n",
    "\n",
    "features = df_train[feature_cols]\n",
    "\n",
    "features[features.isnull()] = 0\n",
    "    \n",
    "label = df_train[target]\n",
    "\n",
    "train_features = features.copy()\n",
    "train_label = label.copy()\n",
    "\n",
    "clf = Ridge(alpha=0.001, max_iter=1000, tol=1e-3, random_state=1234)\n",
    "clf.fit(train_features, train_label)\n",
    "\n",
    "predicted = clf.predict(train_features)\n",
    "expected = label\n",
    "\n",
    "pd.DataFrame.from_dict({\n",
    "    'features': feature_cols,\n",
    "    'std': train_features.std(),\n",
    "    'coef': clf.coef_,\n",
    "    'importance': np.abs(clf.coef_) * train_features.std()\n",
    "})\n",
    "\n",
    "print('Answer:',round(np.sqrt(np.mean((predicted - expected) ** 2)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
